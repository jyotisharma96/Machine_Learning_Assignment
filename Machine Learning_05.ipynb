{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed2575a",
   "metadata": {},
   "source": [
    "1.What are the key tasks that machine learning entails? What does data pre-processing imply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d025e6",
   "metadata": {},
   "source": [
    "Answer- Key tasks under machine learning are :\n",
    "\n",
    "1. Defining an objective\n",
    "2. Collection of data\n",
    "3. Data preprocessing\n",
    "4. Choose the model\n",
    "5. Train model\n",
    "6. Evaluate using performance\n",
    "7. Tune the hyperparameters for best performance\n",
    "8. Produce results\n",
    "\n",
    "\n",
    "Data Pre-processing includes steps to make data ready to be used for machine learning modeling. It includes, but is not limited to data cleaning, standardizing of keywords or headers, taking care of missing values and outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b8385",
   "metadata": {},
   "source": [
    "2.Describe quantitative and qualitative data in depth. Make a distinction between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488cc1f6",
   "metadata": {},
   "source": [
    "Answer- Quantitative data is one that is numerical in nature and has order and mathematical meaning to it. It can be of two types:\n",
    "\n",
    "a. Discrete quantitative data - This type of data has values that come from a countably finite or uncountably finite set. For example: number of planets in Milky Way galaxy. It is generally visualized using bar plots.\n",
    "\n",
    "b. Continous quantitative data - This type of data has values that come from uncountably infinite sets. For example: heights of Indians. It is generally visualized using histograms.\n",
    "\n",
    "Qualitative data is one that can be numerical or string in nature, does not necessarily have order to it but cannot possess mathematical meaning. For example: Blood groups, Grades etc.\n",
    "\n",
    "a. Nominal qualitative data - This type of data is mostly used to label data points based on other characteristics. Nominal data cannot be ordered in any way. For example: Classification of flowers into sub species based on characteristics like sepal length etc.\n",
    "\n",
    "b. Ordinal qualitative data - This type of data is one that can be ordered. For example: Grades.\n",
    "\n",
    "Quantitative data is different from qualitative data as it does not have any numerical nature and do not have mathematical meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374a96d",
   "metadata": {},
   "source": [
    "3.Create a basic data collection that includes some sample records. Have at least one attribute from\n",
    "each of the machine learning data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782f471",
   "metadata": {},
   "source": [
    "Answer- The Basic data collection with sample records, including attributes from different types of machine learning data:\n",
    "\n",
    "Numeric Attribute:\n",
    "\n",
    "Attribute: Age\n",
    "Data Type: Numeric (Continuous)\n",
    "Sample Records:\n",
    "Record 1: Age = 25\n",
    "Record 2: Age = 32\n",
    "Record 3: Age = 45\n",
    "Categorical Attribute:\n",
    "\n",
    "Attribute: Gender\n",
    "Data Type: Categorical (Nominal)\n",
    "Sample Records:\n",
    "Record 1: Gender = Male\n",
    "Record 2: Gender = Female\n",
    "Record 3: Gender = Non-binary\n",
    "Text Attribute:\n",
    "\n",
    "Attribute: Occupation\n",
    "Data Type: Text (Unstructured)\n",
    "Sample Records:\n",
    "Record 1: Occupation = Engineer\n",
    "Record 2: Occupation = Teacher\n",
    "Record 3: Occupation = Doctor\n",
    "Boolean Attribute:\n",
    "\n",
    "Attribute: Subscription\n",
    "Data Type: Boolean\n",
    "Sample Records:\n",
    "Record 1: Subscription = True\n",
    "Record 2: Subscription = False\n",
    "Record 3: Subscription = True\n",
    "Date Attribute:\n",
    "\n",
    "Attribute: Registration Date\n",
    "Data Type: Date/Time\n",
    "Sample Records:\n",
    "Record 1: Registration Date = 2021-05-10\n",
    "Record 2: Registration Date = 2022-01-15\n",
    "Record 3: Registration Date = 2023-07-01\n",
    "Numerical Array Attribute:\n",
    "\n",
    "Attribute: Ratings\n",
    "Data Type: Numeric Array\n",
    "Sample Records:\n",
    "Record 1: Ratings = [4, 5, 3, 4, 2]\n",
    "Record 2: Ratings = [3, 4, 4, 5, 4]\n",
    "Record 3: Ratings = [5, 2, 3, 2, 4]\n",
    "This basic data collection includes various attributes representing different data types commonly used in machine learning. It provides examples of numeric, categorical, text, boolean, date/time, and numerical array attributes, along with corresponding sample records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec0c79",
   "metadata": {},
   "source": [
    "4.What are the various causes of machine learning data issues? What are the ramifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b057bf",
   "metadata": {},
   "source": [
    "Answer- Machine learning data issues can arise from\n",
    "\n",
    "1. Removing outliers from data having non-gaussian distribution.\n",
    "2. Imputing data using numerical averages in case of non gaussian distribution.\n",
    "3. Low number of data points\n",
    "4. Data coming from a sample not representative of the population.\n",
    "5. Improper data entry\n",
    "6. Highly Collinear independent features\n",
    "\n",
    "Ramifications can be overfitting, underfitting and low performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f036880",
   "metadata": {},
   "source": [
    "5.Demonstrate various approaches to categorical data exploration with appropriate examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c0b89",
   "metadata": {},
   "source": [
    "Answer- Various approaches to categorical data exploration are:\n",
    "\n",
    "1. Unique value count: One of the first things which can be useful during data exploration is to see how many unique values are there in categorical columns. \n",
    "\n",
    "\n",
    "2. Frequency Count: Frequency count is finding how frequent individual values occur in column.\n",
    "\n",
    "\n",
    "3. Variance: Variance gives a good indication how the values are spread. \n",
    "\n",
    "\n",
    "4. Pareto Analysis: Pareto analysis is a creative way of focusing on what is important. Pareto 80–20 rule can be effectively used in data exploration. \n",
    "\n",
    "\n",
    "5. Histogram: Histogram are one of the data scientists favourite data exploration techniques. It gives information on the range of values in which most of the values fall. It also gives information on whether there is any skew in data. \n",
    "\n",
    "\n",
    "6. Correlation Heat-map between all numeric columns: The term correlation refers to a mutual relationship or association between two things. \n",
    "\n",
    "\n",
    "7. Pearson Correlation and Trend between two numeric columns: Once you have visualised correlation heat-map , the next step is to see the correlation trend between two specific numeric columns. \n",
    "\n",
    "\n",
    "8. Outlier overview: Finding something unusual in data is called Outlier detection (also known as anomaly detection). These outliers represent something unusual, rare , anomaly or something exceptional.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf4c9a",
   "metadata": {},
   "source": [
    "6.How would the learning activity be affected if certain variables have missing values? Having said\n",
    "that, what can be done about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74389ce7",
   "metadata": {},
   "source": [
    "Answer- Several sklearn algorithms assume that all features are numerical and have mathematical meaning to them. If they come across missing values, the algorithm breaks and the program breaks. Generally, missing data builds up poor performance of the machine learning model. Certain algorithms like Random Forest however can handle missing data, at the expense of performance.\n",
    "\n",
    "Missing values can be imputed if the data has gaussian distribution. If not, median can be used for imputation. Certain values can also be filled using pandas interpolate() that calculates what missing value should be, based on the previous values but this can only work for features like ID code. Another way is to use machine learning models to learn from the data and then fill the missing value with most probable value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e554673",
   "metadata": {},
   "source": [
    "7.Describe the various methods for dealing with missing data values in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e394ad",
   "metadata": {},
   "source": [
    "Answer- Dealing with missing data values is a crucial step in data preprocessing. Several methods can be used to handle missing values, each with its advantages and limitations. Here are some commonly used methods for dealing with missing data:\n",
    "\n",
    "1. Deletion Methods:\n",
    "    \n",
    "a. Listwise Deletion: In this method, any data record with missing values is entirely removed from the dataset. It is the simplest approach but can result in a loss of information if the missing values are not randomly distributed.\n",
    "\n",
    "b. Pairwise Deletion: This method involves using available data for each specific analysis, discarding only the missing values for that particular analysis. It maximizes the use of available data but can lead to varying sample sizes across different analyses.\n",
    "\n",
    "2. Mean/Mode Imputation:\n",
    "    \n",
    "a. Mean Imputation: Missing values in a numeric variable are replaced with the mean of the observed values for that variable. It assumes that the missing values have a similar distribution as the observed values. However, it can distort the mean and standard deviation of the variable.\n",
    "\n",
    "b. Mode Imputation: Missing values in a categorical variable are replaced with the mode (most frequent category) of the observed values. This method is applicable only to categorical variables.\n",
    "\n",
    "3. Median/Most Frequent Imputation:\n",
    "    \n",
    "a. Median Imputation: Missing values in a numeric variable are replaced with the median of the observed values for that variable. It is less sensitive to outliers compared to mean imputation.\n",
    "\n",
    "b. Most Frequent Imputation: Missing values in a categorical variable are replaced with the most frequent category observed for that variable. It works well for variables with skewed distributions.\n",
    "\n",
    "4. Hot Deck Imputation:\n",
    "\n",
    "In this method, missing values are imputed by borrowing values from similar records in the dataset. The similar records are identified based on a set of matching variables. The imputed values are randomly selected from the pool of similar records, ensuring variability.\n",
    "\n",
    "5. Regression Imputation:\n",
    "\n",
    "Missing values are estimated using regression models. A regression model is built with the variable containing missing values as the dependent variable and other variables as predictors. The missing values are then predicted based on the model.\n",
    "\n",
    "6. Multiple Imputation:\n",
    "\n",
    "Multiple imputation creates multiple plausible imputed datasets, where missing values are imputed using advanced techniques like regression imputation or predictive mean matching. The imputed datasets are analyzed separately, and the results are combined using specific rules to account for the uncertainty introduced by imputation.\n",
    "\n",
    "7. Maximum Likelihood Estimation:\n",
    "\n",
    "Maximum likelihood estimation involves using statistical models to estimate the missing values based on the observed data and their relationships. It accounts for the uncertainty associated with missing values and provides unbiased parameter estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d0417",
   "metadata": {},
   "source": [
    "8.What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
    "function selection in a few words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218557f8",
   "metadata": {},
   "source": [
    "Answer- \n",
    "\n",
    "1. __Data preprocessing__- Data preprocessing is the process of transforming raw data into an understandable format. It is also an important step in data mining as we cannot work with raw data. The quality of the data should be checked before applying machine learning or data mining algorithms.\n",
    "\n",
    "\n",
    "2. __Dimensionality reduction__- Dimensionality reduction is a machine learning (ML) or statistical technique of reducing the amount of random variables in a problem by obtaining a set of principal variables.\n",
    "\n",
    "\n",
    "3. __Feature selection__- There are three types of feature selection: Wrapper methods (forward, backward, and stepwise selection), Filter methods (ANOVA, Pearson correlation, variance thresholding), and Embedded methods (Lasso, Ridge, Decision Tree).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f807b7e",
   "metadata": {},
   "source": [
    "9.What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
    "surpass the upper whisker in length? How can box plots be used to identify outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b955ae7",
   "metadata": {},
   "source": [
    "Answer- a) IQR is used to measure variability by dividing a data set into quartiles. The data is sorted in ascending order and split into 4 equal parts. Q1, Q2, Q3 called first, second and third quartiles are the values which separate the 4 equal parts. Q1 represents the 25th percentile of the data.The interquartile range is calculated in much the same way as the range. All you do to find it is subtract the first quartile from the third quartile: IQR = Q3 – Q1. The interquartile range shows how the data is spread about the median.\n",
    "\n",
    "\n",
    "b) A box and whisker plot—also called a box plot—displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ee136",
   "metadata": {},
   "source": [
    "10. Make brief notes on any two of the following:\n",
    "\n",
    "\n",
    "1. Data collected at regular intervals\n",
    "\n",
    "\n",
    "2. The gap between the quartiles\n",
    "\n",
    "\n",
    "3. Use a cross-tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b2bc3",
   "metadata": {},
   "source": [
    "Answer- \n",
    "\n",
    "1. __Data collected at regular intervals__: Data collected at regular intervals refers to a structured data collection process where observations or measurements are recorded systematically at fixed time intervals.\n",
    "This type of data is often used in time series analysis and can provide valuable insights into trends, patterns, and seasonality over time.\n",
    "Examples of data collected at regular intervals include stock prices recorded every hour, temperature measurements taken every day, or sales data collected monthly.\n",
    "Analyzing data collected at regular intervals can involve techniques such as time series forecasting, trend analysis, and seasonality decomposition.\n",
    "\n",
    "\n",
    "\n",
    "2. __The gap between the quartiles__: The gap between the quartiles, also known as the interquartile range (IQR), is a measure of dispersion that represents the spread of the middle 50% of the data.\n",
    "It is calculated by subtracting the first quartile (Q1) from the third quartile (Q3) of a dataset.\n",
    "The IQR provides valuable information about the variability and distribution of the data, particularly in the central portion where the majority of the observations lie.\n",
    "A larger IQR indicates a wider spread or greater variability, while a smaller IQR suggests a narrower spread or lower variability.\n",
    "The IQR is often used in conjunction with box plots to visualize the distribution of data and identify potential outliers.\n",
    "It is a robust measure of dispersion that is less affected by extreme values or outliers compared to the range or standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadf766",
   "metadata": {},
   "source": [
    "11. Make a comparison between:\n",
    "\n",
    "\n",
    "1. Data with nominal and ordinal values\n",
    "\n",
    "\n",
    "2. Histogram and box plot\n",
    "\n",
    "\n",
    "3. The average and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a279fd",
   "metadata": {},
   "source": [
    "Answer- \n",
    "\n",
    "1. __Data with nominal and ordinal values__:\n",
    "\n",
    "Nominal data represents categories or labels without any inherent order or hierarchy. Examples include gender (male/female), colors (red/blue/green), or types of cars (sedan/SUV/hatchback). Nominal data can be represented by labels or numbers, but the order of the values is arbitrary.\n",
    "Ordinal data, on the other hand, represents categories with a meaningful order or hierarchy. Examples include rating scales (1 to 5 stars), educational levels (elementary/middle/high school/college), or satisfaction levels (poor/fair/good/excellent). Ordinal data maintains the order or ranking between the categories.\n",
    "\n",
    "2. __Histogram and box plot__:\n",
    "\n",
    "Histogram and box plot are graphical representations used to describe the distribution of numerical data.\n",
    "A histogram displays the frequency or count of data points within predefined intervals or bins. It provides a visual representation of the data's distribution, including information about the shape, center, and spread. Histograms are useful for understanding the overall pattern of the data, identifying skewness or outliers, and assessing the data's symmetry.\n",
    "\n",
    "A box plot, also known as a box-and-whisker plot, summarizes the distribution of data using quartiles. It displays the median, quartiles (Q1 and Q3), and any potential outliers. The box represents the interquartile range (IQR) and spans the middle 50% of the data. The whiskers extend to the minimum and maximum values within 1.5 times the IQR. Box plots are useful for comparing distributions, identifying skewness or outliers, and visualizing the spread and central tendency of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31408f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8fc1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
